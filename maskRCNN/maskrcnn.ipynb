{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils import BrainDataset\n",
    "\n",
    "# Paths to NIfTI files\n",
    "# list all files in folder data MSSEG-1\n",
    "dataset_path = \"../data/MSSEG-1-preprocessed-2/\"\n",
    "\n",
    "# Create the dataset and dataloader\n",
    "dataset = BrainDataset(root_dir=dataset_path)\n",
    "data_loader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n"
   ],
   "id": "bd5b7beb5015d877"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Fetch a sample from the dataset\n",
    "images, targets = next(iter(data_loader))\n",
    "\n",
    "# Select the first sample\n",
    "image = images[0].squeeze(0).numpy()  # Remove channel dimension\n",
    "mask = targets[0]['masks'][0].numpy()  # Select the first mask\n",
    "\n",
    "# Plot the image slice and the corresponding mask slice\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axes[0].imshow(image, cmap='gray')\n",
    "axes[0].set_title(\"Flair Image Slice\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "axes[1].imshow(mask, cmap='gray')\n",
    "axes[1].set_title(\"Consensus Mask Slice\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "69710c0c445596e9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torchvision\n",
    "\n",
    "num_classes = 2  # Background + 1 class for segmentation\n",
    "\n",
    "model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "# Modify the classifier and mask head for the new dataset\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "hidden_layer = 256\n",
    "model.roi_heads.mask_predictor = torchvision.models.detection.mask_rcnn.MaskRCNNPredictor(    in_features_mask, hidden_layer, num_classes)"
   ],
   "id": "29b23ad9809f0b12"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)"
   ],
   "id": "e12a6db9bf0bb5ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "num_epochs = 10"
   ],
   "id": "22d9b4b2a7f3330e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "best_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for images, targets in data_loader:\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_dict = model(images, targets)\n",
    "\n",
    "        # Check for NaNs in the loss dictionary\n",
    "        for key, value in loss_dict.items():\n",
    "            if torch.isnan(value).any():\n",
    "                print(f\"NaN detected in {key}\")\n",
    "\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        if torch.isnan(losses):\n",
    "            print(\"NaN in overall loss. Skipping batch.\")\n",
    "            continue  # Skip this batch\n",
    "\n",
    "        epoch_loss += losses.item()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    # Save the model if the current epoch's loss is better than the best loss\n",
    "    if epoch_loss < best_loss:\n",
    "        best_loss = epoch_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        print(f\"Model saved with loss: {best_loss:.4f}\")"
   ],
   "id": "e1e06c6cbdf1a1b8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4585bfe206cd1140"
  }
 ],
 "metadata": {},
 "nbformat": 5,
 "nbformat_minor": 9
}
